# Denoising Diffusion Probabilistic Models
## 1.隐变量模型
生成模型需要建模数据的分布 $p(x)$ , 自回归模型和Flow模型都是直接建模分布 $p(x)$ , 隐变量模型则通过引入隐变量z,间接建模分布$p(x)$.
$$
\begin{aligned}
  p(x) &= \int p(x, z)dz \\
       &= \int p(x|z)p(z)dz \\
  log p(x) &= log \int p(x|z)p(z)dz \\
           &= log \int \frac{q(z)}{q(z)}p(x|z)p(z)dz \\
           &\ge E_{z \sim q(z)} [log p(x|z)] - E_{z \sim q(z)}[log q(z) - log p(z)]
\end{aligned}
$$
上式用到了变分推断和Jensen不等式. 那么 $q(z)$ 如何得到?在生成模型中, 通常用 $q(z|x)$ 来代替 $q(z)$ . 于是就有了如下形式:
$$
\begin{aligned}
  log p(x) &= log \int p(x|z)p(z)dz \\
           &= log \int \frac{q(z|x)}{q(z|x)}p(x|z)p(z)dz \\
           &\ge E_{z \sim q(z|x)} [log p(x|z)] - E_{z \sim q(z|x)}[log q(z|x) - log p(z)]
\end{aligned}
$$
上式如何直观的理解呢? 考虑变分自编码器(VAE)生成图像的过程, 在VAE中, 先从数据集中从随机取出一张图像 $x$ , VAE先将 $x$ 通过Encoder编码到隐变量 $z$ , 也就是 $q(z|x)$表示的过程.
